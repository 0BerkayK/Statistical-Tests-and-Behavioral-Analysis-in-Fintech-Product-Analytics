# Fintech ÃœrÃ¼n AnalitiÄŸi â€” Ä°statistiksel Analiz & Test OdaklÄ± Proje

Bu proje, Sipay benzeri bir fintech Ã¼rÃ¼n veri analisti rolÃ¼nÃ¼ simÃ¼le etmek amacÄ±yla hazÄ±rlanmÄ±ÅŸtÄ±r.
AmaÃ§, kullanÄ±cÄ± davranÄ±ÅŸlarÄ±nÄ± ve Ã¼rÃ¼n kullanÄ±mÄ±nÄ± istatistiksel yÃ¶ntemlerle analiz ederek, A/B testlerini, segment bazlÄ± feature adoptionâ€™Ä±, cohort retentionâ€™Ä± ve anomalileri tespit etmek; sonuÃ§larÄ± yÃ¶netim raporlarÄ± ÅŸeklinde sunmaktÄ±r.

Projede kullanÄ±lan veriler simÃ¼le edilmiÅŸ sentetik verilerdir, ancak gerÃ§ek dÃ¼nya senaryolarÄ±na uygun olacak ÅŸekilde tasarlanmÄ±ÅŸtÄ±r.

ğŸ”¹ Proje AdÄ±mlarÄ±

01_data_cleaning.ipynb

Eksik ve hatalÄ± deÄŸerlerin kontrolÃ¼ ve temizlenmesi

Duplicates, outlier ve tip dÃ¶nÃ¼ÅŸÃ¼mleri

02_cohort_retention.ipynb

KullanÄ±cÄ± cohortâ€™larÄ± oluÅŸturma

D1/D7/D30 retention hesaplamalarÄ± ve heatmap gÃ¶rselleÅŸtirme

03_ab_test_analysis.ipynb / ab_test.py

Onboarding veya feature A/B testleri

Proportion z-test ile anlamlÄ±lÄ±k analizi

04_segment_feature_adoption.ipynb

Segment bazlÄ± feature adoption analizi

Chi-square testi

05_anomaly_detection.ipynb / anomaly_alert.py

KPI ve transaction verilerinde olaÄŸandÄ±ÅŸÄ± deÄŸerlerin tespiti

Z-score yÃ¶ntemi ile anomaly detection ve CSV / opsiyonel alert

06_summary_report.ipynb / cohort_calculator.py / weekly_insight_report.md

TÃ¼m analizlerin birleÅŸtirilmesi ve gÃ¶rselleÅŸtirilmesi

YÃ¶netim iÃ§in okunabilir weekly insight report Ã¼retimi
---

## Proje amaÃ§larÄ±

* GerÃ§ekÃ§i (veya sentetik) veri ile **istatistiksel A/B testleri**, **cohort-retention analizi**, **segment & feature adoption analizi**, ve **anomaly detection** gerÃ§ekleÅŸtirmek.
* Her adÄ±m iÃ§in Jupyter notebook + script saÄŸlamak, reproducible ve aÃ§Ä±klayÄ±cÄ± sonuÃ§lar Ã¼retmek.

---

## Ã‡alÄ±ÅŸma dizini

```
fintech_product_analysis/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â”œâ”€â”€ users.csv
â”‚   â”‚   â””â”€â”€ transactions.csv
â”‚   â””â”€â”€ cleaned/
â”‚   â”‚   â”œâ”€â”€ users_cleaned.csv
â”‚   â”‚   â””â”€â”€ transactions_cleaned.csv
â”‚   â”‚   
â”‚   â”œâ”€â”€ ab_test_data.csv
â”‚   â”œâ”€â”€ anomalies_detected.csv
â”‚   â”œâ”€â”€ cohort_analysis.csv
â”‚   â”œâ”€â”€ feature_adoption.csv
â”‚   â”œâ”€â”€ user_segment.csv
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_data_cleaning.ipynb
â”‚   â”œâ”€â”€ 02_cohort_retention.ipynb
â”‚   â”œâ”€â”€ 03_ab_test_analysis.ipynb
â”‚   â”œâ”€â”€ 04_segment_feature_adoption.ipynb
â”‚   â”œâ”€â”€ 05_anomaly_detection.ipynb
â”‚   â””â”€â”€ 06_summary_report.ipynb
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ ab_test.py
â”‚   â”œâ”€â”€ anomaly_alert.py
â”‚   â”œâ”€â”€ generate_segments_adoption.py
â”‚   â””â”€â”€ cohort_calculator.py
â”‚
â”œâ”€â”€ reports/
â”‚   â””â”€â”€ weekly_insight_report.md
â”‚
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

---

## Ã‡alÄ±ÅŸma ortamÄ± kurulumu

1. Sanal ortam oluÅŸturun (venv veya conda)
2. `requirements.txt` iÃ§eriÄŸini yÃ¼kleyin:

```
# Ã¶rnek requirements.txt iÃ§eriÄŸi
pandas
numpy
matplotlib
seaborn
scipy
statsmodels
jupyter
duckdb
sqlalchemy
google-cloud-bigquery      # opsiyonel, BigQuery ile baÄŸlanmak isterseniz
snowflake-connector-python  # opsiyonel
caas_jupyter_tools          # notebook'ta DataFrame gÃ¶sterimi (Ã§alÄ±ÅŸma ortamÄ± iÃ§in)

# zaman serisi/anomali iÃ§in
pmdarima

```

> Not: BigQuery/Snowflake kullanacaksanÄ±z ilgili client kÃ¼tÃ¼phanelerini ekleyin.

---



